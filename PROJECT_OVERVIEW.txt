================================================================================
                         ENIGMA ENGINE - PROJECT OVERVIEW
================================================================================
                           Last Updated: December 2025

WHAT IS THIS?
-------------
Enigma Engine is a modular AI chatbot/assistant framework. It's designed to be 
HARDWARE-AGNOSTIC - running on anything from Raspberry Pi to gaming PC to phone.
Each component (model, memory, voice, GUI, avatar) is isolated so you can easily 
swap parts out for better ones as your project grows.

The engine can:
  - Train and run AI models from scratch (no pretrained required)
  - Manage multiple named AI "personalities"
  - Scale models up/down based on available hardware
  - Communicate across devices (Pi ↔ PC ↔ Phone)
  - See the screen and interact with it
  - Control a 3D avatar character
  - Search the web, read documents, manage files
  - Work on any platform (Windows, Mac, Linux, Android, iOS)


SUPPORTED PLATFORMS
-------------------
✓ Windows PC (with or without GPU)
✓ Mac (Intel or Apple Silicon M1/M2/M3)
✓ Linux (desktop or server)
✓ Raspberry Pi (all models)
✓ Android (via Termux or Pydroid3)
✓ iOS (via Pythonista or a-shell)
✓ Any device with Python 3.8+

The system auto-detects your hardware and recommends optimal settings.


================================================================================
                              FOLDER STRUCTURE
================================================================================

enigma_engine/
│
├── run.py                 Main entry point (--train, --run, --gui, --serve)
├── setup.py               Package installation
├── requirements.txt       Dependencies
├── pytest.ini             Test configuration
├── test_system.py         Quick system tests
│
├── enigma/                *** MAIN PACKAGE ***
│   ├── __init__.py        Package init
│   ├── config.py          Centralized config (paths, settings)
│   │
│   ├── core/              *** BRAIN - Model & AI ***
│   │   ├── model.py       Enigma transformer (RoPE, RMSNorm, SwiGLU)
│   │   ├── training.py    Training loop (AMP, gradient accumulation)
│   │   ├── trainer.py     Advanced trainer (multi-GPU, checkpoints)
│   │   ├── inference.py   EnigmaEngine (generation, streaming, chat)
│   │   ├── tokenizer.py   Character-level tokenizer + dictionary
│   │   ├── layers.py      Legacy neural network components
│   │   ├── model_config.py Model size presets (tiny→xxxl)
│   │   ├── model_registry.py Named model management
│   │   ├── model_scaling.py Grow/shrink/distill models
│   │   ├── hardware.py    Hardware detection & adaptation
│   │   └── nn/            *** MODULAR NN COMPONENTS ***
│   │       ├── attention.py   MHA, GQA, Sliding Window
│   │       ├── activations.py SwiGLU, GeGLU, ReGLU
│   │       ├── normalization.py RMSNorm, AdaptiveRMSNorm
│   │       ├── embeddings.py  RoPE, Sinusoidal, Learned
│   │       └── experts.py     MoE, LoRA, Multi-Query Attention
│   │
│   ├── memory/            *** MEMORY - Storage ***
│   │   ├── manager.py     JSON conversation files
│   │   ├── memory_db.py   SQLite database
│   │   └── vector_utils.py Similarity search
│   │
│   ├── comms/             *** COMMUNICATIONS - Networking ***
│   │   ├── api_server.py  Flask API server
│   │   ├── remote_client.py API client
│   │   ├── network.py     Multi-device communication
│   │   ├── discovery.py   Auto-find other nodes
│   │   ├── memory_sync.py Sync memories across devices
│   │   ├── mobile_api.py  Phone-optimized API
│   │   └── web_server.py  WebSocket server with web UI
│   │
│   ├── gui/               *** INTERFACE - Desktop App ***
│   │   ├── main_window.py Basic PyQt5 window
│   │   └── enhanced_window.py Full-featured GUI (all tabs)
│   │
│   ├── voice/             *** VOICE - Speech ***
│   │   ├── tts_simple.py  Text-to-Speech (pyttsx3)
│   │   └── stt_simple.py  Speech-to-Text (SpeechRecognition)
│   │
│   ├── avatar/            *** AVATAR - Visual Character ***
│   │   ├── avatar_api.py  Simple avatar stub
│   │   └── controller.py  Full avatar system (3D, movement)
│   │
│   ├── tools/             *** TOOLS - AI Capabilities ***
│   │   ├── tool_registry.py Tool framework
│   │   ├── web_tools.py   Web search, fetch pages
│   │   ├── file_tools.py  File operations
│   │   ├── document_tools.py Read PDF, EPUB, DOCX
│   │   ├── system_tools.py Commands, screenshots, info
│   │   ├── vision.py      Screen capture & OCR
│   │   ├── simple_ocr.py  Basic OCR without Tesseract
│   │   └── robot_tools.py Robot/hardware control
│   │
│   ├── config/            *** CONFIGURATION ***
│   │   └── defaults.py    Default settings
│   │
│   └── utils/             *** HELPERS ***
│       └── __init__.py    Utility functions
│
├── scripts/               *** CLI TOOLS ***
│   ├── train.py           Training CLI
│   ├── generate.py        Text generation CLI
│   ├── serve.py           API server launcher
│   ├── convert.py         Model conversion
│   └── benchmark.py       Performance testing
│
├── tests/                 *** TEST SUITE (pytest) ***
│   ├── test_model.py      Model architecture tests
│   ├── test_inference.py  Generation tests
│   ├── test_tools.py      Tool tests
│   ├── test_memory.py     Memory/storage tests
│   ├── test_comms.py      Communication tests
│   └── test_integration.py End-to-end tests
│
├── examples/              *** EXAMPLE SCRIPTS ***
│   ├── basic_usage.py     Simple usage examples
│   ├── chat_example.py    Chat interface example
│   ├── streaming_example.py Token streaming
│   └── api_client_example.py Remote API usage
│
├── data/                  Training data & conversations
├── models/                Saved model files
└── docs/                  Documentation


================================================================================
                    MAJOR FEATURES & CAPABILITIES
================================================================================

1. NAMED AI MODELS
------------------
Create multiple AIs with different personalities:

    from enigma.core.model_registry import ModelRegistry
    
    registry = ModelRegistry()
    registry.create_model("luna", size="medium", description="Creative writer")
    registry.create_model("nova", size="large", description="Technical expert")
    
Each model is fully independent - train them on different data for different skills.


2. MULTI-DEVICE COMMUNICATION
-----------------------------
Run Enigma across devices:

    # On PC (server)
    python examples/multi_device_example.py --server --name pc_brain
    
    # On Pi or Phone (client)
    python examples/multi_device_example.py --client --connect 192.168.1.100:5000
    
    # AI-to-AI conversation
    python examples/multi_device_example.py --conversation --connect 192.168.1.100:5000

Features:
  - Auto-discovery finds nodes on network
  - Memory sync between devices
  - Export/import models via USB (offline sync)


3. PHONE SUPPORT
----------------
Special mobile API optimized for phones:

    from enigma.comms.mobile_api import create_mobile_api
    api = create_mobile_api(port=5000)
    api.run()

Then connect from your phone app. Client code templates included for:
  - Flutter (Dart)
  - React Native (JavaScript)
  - Any HTTP client


4. SCREEN VISION
----------------
AI can see and analyze the screen:

    from enigma.tools.vision import get_screen_vision
    
    vision = get_screen_vision()
    result = vision.see()
    print(result["text_content"])  # OCR'd text
    print(result["description"])   # Scene description
    
    # Find text on screen
    matches = vision.find_text_on_screen("Save")

Requires: PIL/Pillow, optionally pytesseract for OCR


5. AVATAR SYSTEM
----------------
3D character that can move around and interact with screen elements.

    from enigma.avatar.controller import get_avatar, enable_avatar
    
    avatar = get_avatar()
    avatar.enable()              # Turn ON (default is OFF)
    avatar.move_to(500, 300)    # Move to position
    avatar.speak("Hello!")      # Animate speaking
    avatar.interact_with_window("File Manager")  # Visual effect
    avatar.disable()            # Turn OFF

IMPORTANT: Avatar starts OFF by default. Call avatar.enable() to turn on.

Features:
  - On/Off toggle (default: OFF)
  - Move anywhere on screen
  - Expressions (happy, sad, thinking, etc.)
  - "Interact" with windows/files (visual effects)
  - Customizable 3D model (when renderer implemented)


6. TOOL SYSTEM
--------------
AI can use tools:

    from enigma.tools import execute_tool
    
    # Web search
    execute_tool("web_search", query="Python tutorials")
    
    # Read files
    execute_tool("read_file", path="/home/user/notes.txt")
    
    # See screen
    execute_tool("see_screen")
    
    # System info
    execute_tool("get_system_info")

Available tools:
  - web_search: Search the internet
  - fetch_webpage: Get page content
  - read_file, write_file, list_directory, move_file, delete_file
  - read_document: PDF, EPUB, DOCX, TXT
  - run_command: Execute shell commands
  - take_screenshot: Capture screen
  - see_screen: Vision + OCR
  - find_on_screen: Find text/elements


7. MODEL SCALING
----------------
Grow or shrink models based on hardware:

    from enigma.core.model_scaling import grow_registered_model
    
    # Trained on Pi, want to run on PC?
    grow_registered_model("my_model", "small", "large")
    
    # PC model too big for phone?
    shrink_registered_model("my_model", "large", "small")


8. HARDWARE AUTO-DETECTION
--------------------------
System automatically detects:

    from enigma.core.hardware import get_hardware
    
    hw = get_hardware()
    print(hw.summary())
    # Output:
    # Device: Raspberry Pi
    # CPU: ARM Cortex-A76 (4 cores)
    # RAM: 8 GB
    # GPU: None (CPU only)
    # Recommended Model: small


================================================================================
                         MODEL SIZE OPTIONS
================================================================================

  Size    | Params  | RAM    | VRAM  | Best For
  --------|---------|--------|-------|------------------
  tiny    | ~2M     | 1GB    | 0GB   | Testing, Pi Zero, Mobile
  small   | ~15M    | 4GB    | 2GB   | Pi 4/5, Laptops
  medium  | ~50M    | 8GB    | 4GB   | Mid-range GPUs
  large   | ~125M   | 16GB   | 8GB   | Gaming PCs (GPT-2 small)
  xl      | ~350M   | 32GB   | 12GB  | Workstations (GPT-2 medium)
  xxl     | ~770M   | 64GB   | 24GB  | Multi-GPU (GPT-2 large)
  xxxl    | ~1.5B   | 128GB  | 48GB  | Server-scale (GPT-2 XL)


================================================================================
                         QUICK START COMMANDS
================================================================================

# Setup (first time)
cd /home/pi/Documents/project/enigma_engine
source venv/bin/activate

# Basic operations
python run.py --train              # Train model
python run.py --run                # CLI chat
python run.py --gui                # Desktop GUI
python run.py --serve              # API server

# Multi-device
python examples/multi_device_example.py --discover  # Find nodes
python examples/multi_device_example.py --server    # Start server
python examples/multi_device_example.py --client    # Connect

# Hardware info
python -c "from enigma.core.hardware import get_hardware; print(get_hardware().summary())"

# Test tools
python -c "from enigma.tools import execute_tool; print(execute_tool('get_system_info'))"


================================================================================
                    PRE-TESTING CHECKLIST
================================================================================

Before testing the full system, verify each component:

□ 1. ENVIRONMENT
   python --version  # Should be 3.8+
   pip list | grep torch  # PyTorch installed?
   pip list | grep PyQt5  # GUI support?

□ 2. HARDWARE DETECTION
   python -c "from enigma.core.hardware import get_hardware; print(get_hardware().summary())"

□ 3. MODEL CREATION
   python -c "
   from enigma.core.model_registry import ModelRegistry
   r = ModelRegistry()
   r.create_model('test_ai', size='tiny')
   print(r.list_models())
   "

□ 4. TRAINING (quick test)
   python run.py --train

□ 5. INFERENCE
   python run.py --run
   # Type "hello" and press Enter

□ 6. GUI (if display available)
   python run.py --gui

□ 7. API SERVER
   python run.py --serve &
   curl http://127.0.0.1:5000/health

□ 8. TOOLS
   python -c "from enigma.tools import execute_tool; print(execute_tool('get_system_info'))"

□ 9. VOICE (optional)
   python -c "from enigma.voice.tts_simple import TextToSpeech; TextToSpeech().speak('Hello')"

□ 10. SCREEN VISION (if display available)
   python -c "from enigma.tools.vision import get_screen_vision; print(get_screen_vision().see())"

□ 11. AVATAR (optional)
   python -c "
   from enigma.avatar.controller import get_avatar
   a = get_avatar()
   print('Avatar enabled:', a.enable())
   a.disable()
   "

□ 12. MULTI-DEVICE (if 2+ devices available)
   # On device 1: python examples/multi_device_example.py --server
   # On device 2: python examples/multi_device_example.py --discover


================================================================================
                         WHAT'S STILL TODO
================================================================================

CORE FUNCTIONALITY (Ready to use):
✓ Model training & inference
✓ Named model registry
✓ Model scaling
✓ Hardware detection
✓ Multi-device communication
✓ Mobile API
✓ Screen vision
✓ Avatar controller (framework)
✓ Tool system
✓ Voice (TTS)

NEEDS IMPLEMENTATION:
○ Avatar 3D renderer (need PyQt5/OpenGL/PyGame implementation)
○ Speech-to-text (need microphone + model)
○ Tool router (AI choosing which tool to use)
○ Training data pipeline (large corpus handling)
○ Model quantization (for smaller memory footprint)

OPTIONAL ENHANCEMENTS:
○ Better tokenizer (BPE/SentencePiece)
○ Attention visualization
○ Web UI alternative to PyQt5
○ Plugin system for custom tools


================================================================================
                              CONTACT
================================================================================

This project is your foundation - customize it however you want!

Key files to modify:
  - enigma/core/model.py - Change model architecture
  - enigma/avatar/controller.py - Add real 3D rendering
  - enigma/tools/ - Add new tool capabilities
  - data/data.txt - Add training data

================================================================================
